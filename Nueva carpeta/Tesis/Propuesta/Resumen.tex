\section{Introducción} 
El etiquetado o anotado gramatical, también conocido como Part-of-speech tagging, POS tagging o simplemente POST, es el proceso de asignar una etiqueta gramatical a cada una de las palabras de un texto según su categoría léxica. Por ejemplo tomemos la oración siguiente:\\

\noindent \textsl{There is no asbestos in our products now.} \\

\noindent El resultado de etiquetarla gramaticalmente es: \\

\noindent \textsl{There/EX is/VBZ no/DT asbestos/NN in/IN our/PRP products/NNS now/RB ./.}\\

\noindent donde cada palabra está sucedida por una barra oblicua seguida de la etiqueta gramataical asignada. 

Un tagger o etiquetador es un programa que realiza este proceso automáticamente. La mayoría de los taggers actuales utilizan modelos estadísticos. Estos modelos se nutren entrenando el tagger con un texto anotado previamente (corpus de entrenamiento). El rendimiento del tagger (que se mide por las etiquetas asignadas correctamente) es fuertemente dependiente del corpus de entrenamiento utilizado. 

El problema reside en que la generación de corpus de entrenamiento es una tarea muy costosa, por lo tanto la cantidad y calidad de los mismos es limitada. La idea central de esta tesis es la de suplir la falta de corpus de entrenamiento generando una nueva fuente de información a partir de una fuente de información existente: un diccionario.

Generalmente un diccionario contiene la definición de una palabra, una explicación de su significado, algunas características como su pronunciación y particularmente su clase gramatical y uno o más ejemplos que muestran su uso. Por lo tanto, extrayendo todos los ejemplos de un diccionario, se puede generar un corpus anotado parcialmente, es decir, un conjunto de oraciones donde alguna/s de las palabras que comprenden cada oración posee/n una etiqueta gramatical.

\section{Descripción de la propuesta} 
El objetivo de este trabajo como se mencionó anteriormente es generar una nueva fuente de información a partir de un diccionario y luego utilizarla como corpus de entrenamiento intentando mejorar el rendimiento de un tagger.
\\
\\
\noindent El diccionario elegido para el trabajo es Cobuild: Cobuild es un diccionario de la lengua inglesa basado en la información del corpus Bank of English y el corpus Collins. Todos los ejemplos del diccionario Cobuild muestran patrones gramaticales típicos, vocabulario típico y contextos típicos para cada palabra. En consecuencia, Cobuild presenta una cantidad exhaustiva del vocabulario inglés derivado de observaciones directas del lenguaje.
\\
\\
\subsection{Primer etapa} 
La primer etapa consiste en extraer cuidadosamente los ejemplos (que son oraciones completas conteniendo la palabra definida con información léxica) del diccionario Cobuild y generar a partir de estos un corpus parcialmente anotado. Luego se completará el etiquetado del corpus utilizando un etiquetador automático.
\\
\\
\subsection{Segunda etapa} 
La segunda etapa consiste en entrenar los taggers con este nuevo corpus de entrenamiento, etiquetar y luego medir los resultados.

Los taggers que se utilizarán para el entrenamiento y medición son: 

\begin{itemize}
	\item Trigrams'n'Tags tagger (estocástico) 
	\item Stanford tagger (tagger de máxima entropía).
\end{itemize}


Los corpus elegidos para realizar la medición son: 

\begin{itemize}
	\item Wall Street Journal
	\item British National Corpus
\end{itemize}
Ambos pertenecientes a la lengua inglesa (americana y británica respectivamente).

British National Corpus es una colección de 100 millones de palabras provenientes de textos escritos e inglés hablado creado en los 1990s por un consorcio de editores, universidades (Oxford y Lancaster) y la British Library.

Wall Street Journal es un corpus anotado, parte del Penn Treebank, de algo más de 1 millón de palabras.