\chapter{Experimentación} 
\input{1Experimento} 

\section{Segundo experimento: Etiquetar el corpus WSJ} 
El segundo experimento realizado tiene como objetivo evaluar la nueva fuente de información obtenida (NFI) como corpus de entrenamiento. Para esto se entrenará el etiquetador gramatical TnT y se etiquetará con él el corpus Wall Street Journal (WSJ). Posteriormente se realizarán mediciones de desempeño pertinentes.
\input{EtiquetarWSJconTnT} 

\section{Experimentos adicionales} 
Se realizaron experimentos similares al descripto en la sección anterior para explorar la existencia de variaciones en los resultados a partir de la utilización de otro corpus u otro etiquetador gramatical.
En tal sentido se empleó el etiquetador gramatical automático de máxima entropía Stanford Tagger. También se repitieron los mismos experimentos utilizando ambos etiquetadores gramaticales (Stanford Tagger y TnT) sobre el corpus BNC.

Los experimentos consistieron en comparar el resultado de ejecutar el etiquetador gramatical entrenado con WSJ vs WSJ más la incorporación de la nueva fuente de información generada (NFI) sobre el corpus. Se realizó este mismo experimento sobre particiones; mitades, cuartos y décimos del corpus, intentando encontrar variaciones.

Para todos los casos se observaron resultados similares; un leve aumento del porcentaje de aciertos en el modelo que incorpora NFI. 
El porcentaje de aciertos aumenta a medida que la partición es menor.

Los datos y el detalle de estos experimentos se puede consultar en el apéndice.

\chapter{Conclusiones} 
Se realizó un gran esfuerzo en el preprocesamiento del diccionario Cobuild. A partir de un archivo con formato desconocido la primera etapa consistió en identificar cada entrada y hacer que el archivo fuera legible. En las etapas siguientes se enfocó el esfuerzo en descifrar el formato de cada entrada y en entender la información gramatical obtenida. 

Se crearon algoritmos para poder distinguir ejemplos de definiciones y se verificó el correcto funcionamiento de los mismos. Se detectaron errores de extracción de etiquetas para ciertos casos particulares, por consiguiente se realizaron ajustes en los algoritmos hasta obtener resultados satisfactorios.

Partiendo del hecho de que las etiquetas de Cobuild no poseen un formato conocido ni pertenecen a ningún conjunto de etiquetas documentado, hubo que decidir como realizar la conversión a etiquetas Penn Treebank. El primer análisis determinó que Cobuild posee más de 4000 etiquetas, por lo tanto se realizó un relevamiento de las etiquetas de mayor ocurrencia, que fueron incluídas en la tabla de conversión junto con la etiqueta Penn Treebank equivalente.

Cabe aclarar que las etiquetas Penn Treebank poseen un nivel de detalle gramatical menor a las etiquetas de Cobuild (que son muy ricas gramaticalmente), en consecuencia se produjo una pérdida natural de información en la tarea de mapeo.

Se tuvieron en cuenta palabras derivadas y cuando fué posible (cuando no hubo ambiguedad) se infirieron etiquetas para las mismas. Se realizaron trabajos de verificación de etiquetado, etiquetando automáticamente Cobuild para luego analizar las diferencias contra el resultado del proceso de traducción de etiquetas. 

En muchos casos se analizaron palabras particulares donde las etiquetas no coincidían. Se corrigieron las traducciones y se ajustaron los algoritmos hasta alcanzar un grado de error mínimo.

Como consecuencia de este trabajo de tesis y con el objetivo de medir los resultados obtenidos se ha desarrollado un generador de matrices de confusión con salida opcional para \LaTeX. Esta herramienta es configurable y puede mostrar una cantidad arbitraria de etiquetas de mayor error dentro de la matriz. También posee la capacidad de exhibir las palabras (y la cantidad de veces que ocurren) para cada par de etiquetas contenidas en la matriz. Ninguna de estas características fué encontrada en generadores de matrices de confusión clásicos.

Utilizar un diccionario como nueva fuente de información, convirtiéndolo en un corpus de entrenamiento para etiquetadores gramaticales aumenta levemente el rendimiento final del etiquetado. Esto es cierto incluso para etiquetadores de distintas bases teóricas (máxima entropía y modelos ocultos de Markov).
Las mejoras no logran ser significativas y aumentan tímidamente los valores del resultado final. 

Esto puede suceder ya que la cantidad de información gramatical que agrega un diccionario no es tan considerable; asciende a un valor cercano al 10\% de etiquetas por palabra, es decir que de cada 100 palabras que se extraen de los ejemplos del diccionario solo 10 poseen una etiqueta gramatical.

Este trabajo de tesis deja como aporte una nueva fuente de información semántica producida a partir de Cobuild, la cual puede ser utilizada en trabajos futuros. Dicha fuente de información es pública y se encuentra disponible en COMPLETAR. También todo el código utilizado para realizar las tareas de extracción, traducción de etiquetas, etiquetado, medición y generación de matrices de confusión es público y se encuentra disponible en COMPLETAR