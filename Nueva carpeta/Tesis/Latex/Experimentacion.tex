\chapter{Experimentación} 
\input{1Experimento} 

\newpage
\section{Segundo experimento: Etiquetar el corpus WSJ} 
El segundo experimento realizado tiene como objetivo evaluar la nueva fuente de información obtenida (NFI) como corpus de entrenamiento. Para esto se entrenarán 2 etiquetadores gramaticales (Stanford Tagger y TnT) y se etiquetará con ellos el corpus Wall Street Journal (WSJ). Posteriormente se realizarán mediciones de desempeño pertinentes.
\input{EtiquetarWSJconTnT} 
\newpage
\input{EtiquetarWSJconStanford} 
\newpage

\section{Tercer experimento: Etiquetar el corpus BNC} 
El tercer experimento realizado tiene como objetivo evaluar la nueva fuente de información obtenida (NFI) como corpus de entrenamiento. Para esto se entrenarán 2 etiquetadores gramaticales (Stanford Tagger y TnT) y se etiquetará con ellos el British National Corpus (BNC).
\input{EtiquetarBNCconTnT} 
\newpage
\input{EtiquetarBNCconStanford} 
\newpage

\chapter{Conclusiones} 
Utilizar un diccionario como nueva fuente de información, convirtiéndolo en un corpus de entrenamiento para etiquetadores gramaticales aumenta levemente el rendimiento final del etiquetado. Esto es cierto incluso para etiquetadores de distintas bases teóricas (máxima entropía y modelos ocultos de Markov).
Las mejoras no logran ser significativas y aumentan tímidamente los valores del resultado final. 

Esto puede suceder ya que la cantidad de información gramatical que agrega un diccionario no es tan considerable; asciende a un valor cercano al 8\% de etiquetas por palabra, es decir que de cada 100 palabras que se extraen de los ejemplos del diccionario solo 8 poseen una etiqueta gramatical.

