\chapter{Experimentación} 
\input{1Experimento} 

\section{Segundo experimento: Etiquetar el corpus WSJ} 
El segundo experimento realizado tiene como objetivo evaluar la nueva fuente de información obtenida (NFI) como corpus de entrenamiento. Para esto se entrenará el etiquetador gramatical TnT y se etiquetará con él el corpus Wall Street Journal (WSJ). Posteriormente se realizarán mediciones de desempeño pertinentes.
\input{EtiquetarWSJconTnT} 

\section{Experimentos adicionales} 
Se realizaron experimentos similares al descripto en la sección anterior para explorar la existencia de variaciones en los resultados a partir de la utilización de otro corpus u otro etiquetador gramatical.
En tal sentido se empleó el etiquetador gramatical automático de máxima entropía Stanford Tagger. También se repitieron los mismos experimentos utilizando ambos etiquetadores gramaticales (Stanford Tagger y TnT) sobre el corpus BNC.

Los experimentos consistieron en comparar el resultado de ejecutar el etiquetador gramatical entrenado con WSJ vs WSJ más la incorporación de la nueva fuente de información generada (NFI) sobre el corpus. Se realizó este mismo experimento sobre particiones; mitades, cuartos y décimos del corpus, intentando encontrar variaciones.

Para todos los casos se observaron resultados similares; un leve aumento del porcentaje de aciertos en el modelo que incorpora NFI. 
El porcentaje de aciertos aumenta a medida que la partición es menor.

Los datos y el detalle de estos experimentos se puede consultar en el apéndice.

\chapter{Conclusiones} 
Se realizó un gran esfuerzo en el preprocesamiento del diccionario Cobuild. A partir de un archivo con formato desconocido la primer etapa fué identificar cada entrada y hacer que el archivo fuera legible. Las etapas siguientes consistieron en descifrar el formato de cada entrada y entender como aparecía la información gramatical. Hubo que crear algoritmos para poder distinguir ejemplos de definiciones y verificar el correcto funcionamiento de los mismos sobre una extensa cantidad de entradas. En ciertos casos las etiquetas eran mal asignadas dentro del diccionario con lo cual hubo que reajustar los algoritmos hasta que dieran un resultado satisfactorio. 

La traducción de etiquetas representó otra etapa compleja dentro de este trabajo ya que hubo que tomar muchas decisiones no triviales: se tuvieron en cuenta palabras derivadas y cuando fué posible (cuando no hubo ambiguedad) se infirieron etiquetas para las mismas. Se realizaron trabajos de verificación de etiquetado, etiquetando automáticamente Cobuild para luego analizar las diferencias con la extracción y traducción de etiquetas. En muchos casos se analizaron palabras particulares donde las etiquetas no coincidían. Se corrigieron las traducciones y se ajustaron los algoritmos del proceso de extracción y traducción hasta alcanzar un grado de error mínimo.

A partir del hecho de que las etiquetas de Cobuild no poseen un formato conocido ni pertenecen a ningún conjunto de etiquetas documentado, hubo que decidir como realizar la conversión a etiquetas Penn Treebank. El primer análisis determinó que Cobuild posee más de 4000 etiquetas, con lo cual hubo que discriminar aquellas que aparecieran más frecuentemente. En este sentido se realizó un relevamiento de las etiquetas más frecuentes, las cuales fueron incluídas en la tabla de conversión junto con la etiqueta Penn Treebank equivalente.
Cabe aclarar que las etiquetas Penn Treebank poseen un nivel de detalle gramatical menor a las etiquetas de Cobuild (que son muy ricas gramaticalmente), por lo tanto se produjo una pérdida de información en la tarea de mapeo.

Como consecuencia de este trabajo de tesis y con el objetivo de medir los resultados obtenidos se ha desarrollado un generador de matrices de confusión con salida opcional para Latex. Esta herramienta es configurable y puede mostrar una cantidad arbitraria de etiquetas de mayor error dentro de la matriz. También posee la capacidad de exhibir las palabras (y la cantidad de veces que ocurren) para cada par de etiquetas contenidas en la matriz. Ninguna de estas características fué encontrada en generadores de matrices de confusión clásicos.

Utilizar un diccionario como nueva fuente de información, convirtiéndolo en un corpus de entrenamiento para etiquetadores gramaticales aumenta levemente el rendimiento final del etiquetado. Esto es cierto incluso para etiquetadores de distintas bases teóricas (máxima entropía y modelos ocultos de Markov).
Las mejoras no logran ser significativas y aumentan tímidamente los valores del resultado final. 

Esto puede suceder ya que la cantidad de información gramatical que agrega un diccionario no es tan considerable; asciende a un valor cercano al 8\% de etiquetas por palabra, es decir que de cada 100 palabras que se extraen de los ejemplos del diccionario solo 8 poseen una etiqueta gramatical.

Este trabajo de tesis deja como aporte una nueva fuente de información semántica producida a partir de Cobuild, la cual puede ser utilizada en trabajos futuros. Dicha fuente de información es pública y se encuentra disponible en COMPLETAR. También todo el código utilizado para realizar las tareas de extracción, etiquetado, medición y generación de matrices de confusión es público y se encuentra disponible en COMPLETAR