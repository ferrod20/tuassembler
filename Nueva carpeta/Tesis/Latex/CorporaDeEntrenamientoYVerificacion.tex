\subsection{Corpora de entrenamiento y corpora de verificación} 
En los etiquetadores gramaticales que se basan en modelos estocásticos, las probabilidades se obtienen de un corpus en el que se han entrenado. 

Este corpus de entrenamiento necesita ser cuidadosamente considerado. Si el corpus de entrenamiento es muy específico al dominio, las probailidades van a ser muy estrechas y no generalizarán bien la etiquetación de oraciones en diferentes dominios. Pero si el corpus de entrenamiento es muy general, estas probabilidades no van a hacer el trabajo suficiente de reflejar eldominio.

Supongamos que estamos intentando etiquetar una oración de particular. Si nuestra oración es parte del corpus de entrenamiento, las probabilidades de las etiquetas para esa oración van a ser extraordinariamente precisas y vamos a sobreestimar la precisión de nuestro etiquetador. Se desprende como conclusión que el corpus de entrenamiento no debe ser parcial incluyendo esa oración. Por lo tanto al trabajar con etiquetadores basados en modelos estocásticos, dado un corpus de datos relevante, es una tarea habitual dividir los datos en un corpus de entrenamiento y un corpus de verificación. 

Luego se entrena el etiquetador con el corpus de entrenamiento y como próximo paso se ejecuta el proceso de etiquetación y se comparan los resultados con el corpus de verificación.

En general existen dos métodos para entrenar y verificar un etiquetador gramatical. En el primer método, se divide el corpus disponible en tres partes: un corpus de entrenamiento, un corpus de test y un corpus de test de desarrollo. Se entrena el etiquetador con el corpus de entrenamiento. Entonces se utiliza el conjunto de test de desarrollo (también llamado devtest) para eventualmente afinar o ajustar algunos parámetros y en general decidir cual es el mejor modelo. Una vez que se elige el supuesto mejor modelo, se corre en el corpus de verificación para ver su rendimiento.

En el segundo método de entrenamiento y verificación, se elige aleatoreamente una división de corpus de entrenamiento y verificación para nuestros datos. Se entrena el etiquetador y luego se computa la proporción de error en el corpus de verificación. A continuación se repite con un conjunto de entrenamiento y de  verificacion diferente seleccionado aleatoreamente. 

La repetición de este proceso, llamado validación cruzada generalmente es realizada 10 veces. Luego se promedian esas 10 corridas para obtener un promedio n la proporción del error.

Al comparar modelos es importante utilizar verificaciones estadísticas para determinar si la diferencia entre los modelos es significantiva.
