\section{Primer experimento} 
El primer experimento consiste en medir (generando una matriz de confusión) la información extraída de Cobuild contra la misma información generada a partir de un etiquetador automático (TnT). De esta manera podremos observar la diferencia entre la información gramatical de Cobuild y la información que se podría generar automáticamente.

Como se mencionó anteriormente la información extraída de Cobuild, es la unión de ejemplos con la información gramatical correspondiente a la palabra definida.
A continuación se presenta un pequeño extracto:\\\\
\noindent{\small
\begin{tabular}{l l}
Cats	&NNS \\
are\\
often\\
kept\\
as\\
pets\\
.\\
She\\
put\\
out\\
a\\
hand\\
and\\
stroked\\
the\\
cat	&NN\\
softly\\
...\\
...\\
domestic\\
animals\\
such\\
as\\
dogs\\
and\\
cats	&NNS\\
.\\
\end{tabular}}
\\\\
Esta es la información extraída de Cobuild para la palabra \emph{cat}; la unión de los ejemplos\\
\\
\emph{Cats are often kept as pets.}\\
\emph{She put out a hand and stroked the cat softly...}\\
\emph{...domestic animals such as dogs and cats.}\\
\\
Se puede notar la información gramatical expresada mediante las etiquetas NN y NNS para las palabras \emph{cat} y \emph{cats} respectivamente.
La idea de este experimento será comparar estas etiquetas contra las etiquetas asignadas por el etiquetador automático TnT. Entonces se tomará este corpus plano (sin etiquetas), se lo etiquetará utilizando TnT entrenado con el corpus de entrenamiento Wall Street Journal (de ahora en más WSJ) \footnote{Wall Street Journal es un corpus anotado, parte del Penn Treebank} y luego se realizará la comparación.\\
La matriz de confusión\footnote{Las matrices de confusión presentadas de aquí en adelante contienen las primeras 10 etiquetas de mayor error} generada a partir de dicha comparación es la siguiente:

\input{../Tesis/Bin/Debug/Datos/Extraccion/Cobuild2Pasada.l}


Se puede apreciar un alto porcentaje de aciertos entre las etiquetas extraídas de Cobuild (86,75\%) y las etiquetas asignadas por TnT. Este porcentaje indica que la información de etiquetas extraídas de Cobuild es consistente con las producidas por TnT. La mayoría de los errores se da en etiquetas VB, NN y JJ de Cobuild cuando son etiquetadas como NN, JJ y VBN por TnT respectivamente.
A continuación se muestran algunas ejemplos de los errores:\\\\

\noindent Etiquetado por TnT como NN pero extraído como VB de Cobuild
\begin{itemize}
	\item \textbf{share}: Lets share	the petrol costs...
	\item \textbf{name}: Name	the place, well be there...
\end{itemize}	
	
\noindent Etiquetado por TnT como JJ pero extraído como NN de Cobuild
\begin{itemize}
	\item \textbf{flat}: A flat usually includes a kitchen and bathroom.
	\item \textbf{wireless}: messages sent by cable or wireless
\end{itemize}	
\noindent Etiquetado por TnT como NN pero extraído como JJ de Cobuild
\begin{itemize}
	\item \textbf{firm}: Bake the cake for about an hour until it is firm and brown
	\item \textbf{kind}: I find them all very pleasant and extremely kind and helpful
\end{itemize}	

\noindent Etiquetado por TnT como VBN pero extraído como JJ de Cobuild		
\begin{itemize}
	\item \textbf{settled}: They are practising settled agriculture
\end{itemize}	